---
layout: post
title: Ethics in Data Science. Adressing ethical issues in Machine Learning Models.
cover-img: /assets/img/dark_and_light.jpg
tags: [data science, machine learning, ethics, philosophy]
---

Innovation is driven by data and IT in almost every industry with data science influencing how business is done. Data science lacking ethical considerations like privacy protection, implicit bias or social impacts of automation is a dangerous weapon. Academic papers deliver some evidence that machine bias is an inevitable result of the cultural background and socialization of developers and data scientists who design and implement appropriate algorithmic processes (Palasi/Spielkamp 2017). Bias can enter a system either through the explicit and conscious efforts of individuals or institutions, or implicitly and unconsciously, even in spite of the best of intentions (Friedman/Nissenbaum 1996). I would like to wrap up the recent disussion and reflect some interesting philosophical statements on AI. 

Title image: <span><a href="https://unsplash.com/@nguyendqnhu?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Nhu Nguyen</a> on <a href="https://unsplash.com/s/photos/dark-and-light?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></span>

Ethics in algorithms is one of a few hype topics in data science at the moment. Ethics often comes combined with explainability of machine learning models. When ethical ml algorithms come into our minds we often think about self driving cars calculating the value of two lives against another, killer drones deciding whom to kill or facebook's algorithms being game changers in electional campaigns. For common people the decisions of these algorithms are hard to understand and sometimes it is nearly impossible to do so. But in the last decade machine learning and AI have become very influencial decision makers determine the way we live.

Decisions of algorithms changing our lives in one or another direction have become pervasive and we can tackle ethics in ml on a much more ordinary level. The story of algorithms learning racist or discriminating behavior from human decisions in products of insurance companies is long told. The self-fulfilling prophecy of predictive policing in some neighborhoods and media algorithms in the war on humane attention are other examples from the dark side. The latest summit on AI hosted by the International Social Security Association showed that governmental organisations are well aware of the problem trying to work on it in different ways while expanding their endeavors deploying more and more algorithms.

![ray](/assets/img/ray.jpg)
<span>Photo by <a href="https://unsplash.com/@cristian_newman?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Cristian Newman</a> on <a href="https://unsplash.com/s/photos/dark-and-light?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></span>

A growing number of small and medium companies using ml algorithms oblige on codes of ethics while data driven companies built up specific knowledge on ethical questions in data usage. These codes emphasis on end-to-end coordination of data related processes, data governance as management principle and the responsibility of data scientist training ml models. They are designed to help with decision on different levels of involvement and stimulate discussions on ethical questions when using data in a business model. (who doesn't?) 

Most tend to define some guiding lines when working with data and machine learning algorithms. They proclaim transparency and convict incentive systems designed to gather as much information as possible. Data protection is requested, bias is to be avoided, comprehensibility is promoted and personal responsibility is reinforced. Guiding lines proclaim a right to appeal against the decision of an algorithm and request for the understanding and communication of model limitations. For Switzerland you can visit [DATA SERVICE ALLIANCE](https://data-service-alliance.ch) to work through the Ethical Code for Data-Based Business.

![matrix](/assets/img/matrix.jpg)
<span>Photo by <a href="https://unsplash.com/@markusspiske?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Markus Spiske</a> on <a href="https://unsplash.com/s/photos/algorithm?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></span>

Philosopher Richard David Precht takes a slightly different position when thinking about AI. He emphasizes that ethical programming means crossing a tremendous border. Moral decisions induce highly emotional humane reactions, algorithms on the other side are non-emotional by design and incapable of these kinds of free decisions. Precht works with the example of self driving cars in extreme situations calculating the value of a live against another to decide which pedestrian to kill. Self driving cars are often seen as chance to dramatically reduce traffic death rates but Precht states there are other possibilies like less traffic or slower driving. Gradings in a life's value are not protected by constitutions for some good reason. Precht demands for red lines in every situation AI decides on the loves of humans.

Interesting research is done by algorithmwatch.org, a non-profit organization with the goal of studying and classifying processes of algorithmic decision making that have social relevance - i.e. that either predict or predetermine human decisions, or make decisions automatically. The organization focusses on governmental algorithms but also on monitoring the Instagram algorithm.

To dive much deeper into an important debate I recommend reading the interview with Richard David Precht in T3N61/2020, visit [algorithmwatch](https://algorithmwatch.org) and to participate in debates on ethical AI in your industry.

***Thank you, and have a beautiful day!***
